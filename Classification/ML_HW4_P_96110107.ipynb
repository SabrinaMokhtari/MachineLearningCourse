{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Monetary</th>\n",
       "      <th>Time</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1750</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2250</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency  Frequency  Monetary  Time  tag\n",
       "0        2         50     12500    98    1\n",
       "1        0         13      3250    28    1\n",
       "2        1         16      4000    35    1\n",
       "3        2         20      5000    45    1\n",
       "4        1         24      6000    77    0\n",
       "5        4          4      1000     4    0\n",
       "6        2          7      1750    14    1\n",
       "7        1         12      3000    35    0\n",
       "8        2          9      2250    22    1\n",
       "9        5         46     11500    98    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('transfusion.data')\n",
    "df.columns = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation Metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion(y_pred, y_true, n):\n",
    "    confusion = np.zeros((2, 2))\n",
    "    for i in range(n):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            confusion[0][0] += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "            confusion[0][1] += 1\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0:\n",
    "            confusion[1][0] += 1\n",
    "        else:\n",
    "            confusion[1][1] += 1\n",
    "    return confusion\n",
    "\n",
    "def accuracy_score(cnf):\n",
    "    return (cnf[0][0] + cnf[1][1]) / np.sum(cnf)\n",
    "\n",
    "def recall_score(cnf):\n",
    "    return (cnf[0][0]) / (cnf[0][0] + cnf[1][0])\n",
    "\n",
    "def precision_score(cnf):\n",
    "    return (cnf[0][0]) / (cnf[0][0] + cnf[0][1])\n",
    "\n",
    "def f1_score(cnf):\n",
    "    r = recall_score(cnf)\n",
    "    p = precision_score(cnf)\n",
    "    return (2 * p * r) / (r + p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((598, 4), (598,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.sample(frac=0.8, random_state=0)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "x_train = train.loc[:, ['Recency', 'Frequency', 'Monetary', 'Time']]\n",
    "x_train_array = np.array(x_train)\n",
    "y_train = train['tag']\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "x_test = test.loc[:, ['Recency', 'Frequency', 'Monetary', 'Time']]\n",
    "x_test_array = np.array(x_test)\n",
    "y_test = test['tag']\n",
    "y_test_array = np.array(y_test)\n",
    "x_train_array.shape, y_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: \n",
      "accuracy_score: 0.7533333333333333 f1_score:  0.1395348837209302 recall_score:  0.07894736842105263\n",
      "TRAIN: \n",
      "accuracy_score: 0.774247491638796 f1_score:  0.21965317919075142 recall_score:  0.1357142857142857\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(a):\n",
    "    return 1/(1+ np.exp(-1 * a))\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, lr, max_iter):\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        \n",
    "    def predict(self, x):\n",
    "        z = sigmoid(np.dot(x, self.w) + self.w0)\n",
    "        return np.where(z > 0.5, 1, 0)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w0 = 0\n",
    "        self.n = x.shape[0]\n",
    "        self.m = x.shape[1]\n",
    "        self.w = np.zeros(self.m)\n",
    "        for i in range(self.max_iter):\n",
    "            yn = sigmoid(np.dot(self.x, self.w) + self.w0)\n",
    "            tmp = (yn - self.y)\n",
    "            self.w -= self.lr * (np.dot(self.x.T, tmp) / self.n)\n",
    "            self.w0 -= self.lr * (np.sum(tmp) / self.n)\n",
    "        return self\n",
    "\n",
    "\n",
    "model = LogisticRegression(lr=0.1, max_iter=20000)\n",
    "model.fit(x_train_array, y_train_array)\n",
    "y_pred = model.predict(x_test_array)\n",
    "\n",
    "print(\"TEST: \")\n",
    "test_cnf = calc_confusion(y_pred, y_test_array, y_test_array.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(test_cnf), \"f1_score: \", f1_score(test_cnf), \"recall_score: \", recall_score(test_cnf))\n",
    "\n",
    "train_y_pred = model.predict(x_train_array)\n",
    "print(\"TRAIN: \")\n",
    "train_cnf = calc_confusion(train_y_pred, y_train_array, y_train_array.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(train_cnf), \"f1_score: \", f1_score(train_cnf), \"recall_score: \", recall_score(train_cnf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Decision Tree </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_series = df.select_dtypes(np.number).stack().groupby(level=1)\n",
    "numeric_df = numeric_series.describe()\n",
    "numeric_df.insert(8, \"var\", numeric_series.var(), True)\n",
    "numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 8))\n",
    "plt.hist(df['Recency'], density=False, ec='w');\n",
    "\n",
    "plt.figure(figsize=(5, 8))\n",
    "plt.hist(df['Monetary'], density=False, ec='w');\n",
    "\n",
    "plt.figure(figsize=(5, 8))\n",
    "plt.hist(df['Frequency'], density=False, ec='w');\n",
    "\n",
    "plt.figure(figsize=(5, 8))\n",
    "plt.hist(df['Time'], density=False, ec='w');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(df):\n",
    "    train = df.sample(frac=0.8, random_state=0)\n",
    "    test = df.drop(train.index)\n",
    "\n",
    "    x_train = train.loc[:, ['Recency', 'Frequency', 'Monetary', 'Time']]\n",
    "    x_train_array = np.array(x_train)\n",
    "    y_train = train['tag']\n",
    "    y_train_array = np.array(y_train)\n",
    "\n",
    "    x_test = test.loc[:, ['Recency', 'Frequency', 'Monetary', 'Time']]\n",
    "    x_test_array = np.array(x_test)\n",
    "    y_test = test['tag']\n",
    "    y_test_array = np.array(y_test)\n",
    "    return train, test\n",
    "\n",
    "def split_x_y_data(df):\n",
    "\n",
    "    x = df.loc[:, ['Recency', 'Frequency', 'Monetary', 'Time']]\n",
    "    x_array = np.array(x)\n",
    "    y = df['tag']\n",
    "    y_array = np.array(y)\n",
    "    \n",
    "    return x_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "accuracy_score: 0.7725752508361204 f1_score:  0.08108108108108107 recall_score:  0.04285714285714286\n",
      "TEST:\n",
      "accuracy_score: 0.7533333333333333 f1_score:  0.05128205128205127 recall_score:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    TARGET = 'tag'\n",
    "    PRIME = '_prime'\n",
    "    Q = 'q'\n",
    "    YES = 1\n",
    "    NO = 0\n",
    "    N = 2\n",
    "    headers = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "\n",
    "\n",
    "def change_data_set(df, n):\n",
    "    for column in df.columns:\n",
    "        if column == Config.TARGET:\n",
    "            continue\n",
    "\n",
    "        def f(x):\n",
    "            min_value = df[column].min()\n",
    "            max_value = df[column].max()\n",
    "            step = (max_value - min_value) / n\n",
    "            a = min_value\n",
    "            b = a + step\n",
    "            if x < a:\n",
    "                return str(Config.Q) + \"0\"\n",
    "            for i in range(1, n):\n",
    "                if b > x >= a:\n",
    "                    return str(Config.Q) + str(i)\n",
    "                a = b\n",
    "                b = a + step\n",
    "\n",
    "            if x >= a:\n",
    "                return str(Config.Q) + str(n)\n",
    "\n",
    "        df[column + str(Config.PRIME)] = df[column].apply(lambda x: f(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Config.headers)):\n",
    "    if Config.headers[i] == Config.TARGET:\n",
    "        continue\n",
    "    Config.headers[i] = str(Config.headers[i]) + str(Config.PRIME)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, column, df):\n",
    "        self.column = column\n",
    "        self.column_possible_values = df[column].value_counts().index.tolist()\n",
    "        self.num_possible_values = len(df[column].value_counts().index.tolist())\n",
    "        self.gain_information = 0\n",
    "        self.branches_entropy = []\n",
    "\n",
    "    def partition(self, df):\n",
    "        output = list()\n",
    "        for possible_value in self.column_possible_values:\n",
    "            temp = df[df[self.column] == possible_value]\n",
    "            output.append(temp)\n",
    "        return output\n",
    "\n",
    "    def match_index(self, row):\n",
    "        df_row = row\n",
    "        row_answer_value = df_row[self.column]\n",
    "        return self.column_possible_values.index(row_answer_value)\n",
    "\n",
    "    def print(self, spacing):\n",
    "        return \"??\" + str(self.column) + \"??\\n\" + str(spacing) + \" GI: \" + str(\n",
    "            self.gain_information) + \"\\n \" + str(spacing) + \"Branches entropy: \" + str(self.branches_entropy)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"??\" + str(self.column) + \"??\"\n",
    "\n",
    "def B(q):\n",
    "    if q == 1 or q == 0:\n",
    "        return 0\n",
    "    return round(-1 * (q * np.log2(q) + (1 - q) * np.log2(1 - q)), 10)\n",
    "\n",
    "\n",
    "def remainder_util(total_elements, n_k, p_k):\n",
    "    return round((p_k + n_k) / total_elements * B(p_k / (p_k + n_k)), 10)\n",
    "\n",
    "\n",
    "def reminder(total_elements, list_of_partitions):\n",
    "    r = 0\n",
    "    partitions_entropy = []\n",
    "    for sub_df in list_of_partitions:\n",
    "        n_k_and_pk = sub_df.shape[0]\n",
    "        pk = sub_df[sub_df[Config.TARGET] == Config.YES].shape[0]\n",
    "        nk = n_k_and_pk - pk\n",
    "        t = remainder_util(total_elements, nk, pk)\n",
    "        r += t\n",
    "        partitions_entropy.append(t)\n",
    "    return r, partitions_entropy\n",
    "\n",
    "\n",
    "\n",
    "def gain(n, p, list_of_partitions):\n",
    "    r, partitions_entropy = reminder(p + n, list_of_partitions)\n",
    "    return (B(p / (n + p)) - r), partitions_entropy\n",
    "\n",
    "\n",
    "\n",
    "def find_best_split(df):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    n_and_p = df.shape[0]\n",
    "    p = df[df[Config.TARGET] == Config.YES].shape[0]\n",
    "    n = n_and_p - p\n",
    "\n",
    "    for feature in Config.headers[:-1]:\n",
    "        question = Question(feature, df)\n",
    "        question.gain_information, question.branches_entropy = gain(n, p, question.partition(df))\n",
    "        if question.gain_information > best_gain:\n",
    "            best_gain, best_question = question.gain_information, question\n",
    "    return best_gain, best_question\n",
    "\n",
    "\n",
    "def leaf_count(df):\n",
    "    unique_values_count = np.array(df[Config.TARGET].value_counts())\n",
    "    unique_values_name = df[Config.TARGET].value_counts().index.tolist()\n",
    "    counts = {}\n",
    "    for i, name in enumerate(unique_values_name):\n",
    "        counts[name] = unique_values_count[i]\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, df):\n",
    "        self.predictions = leaf_count(df)\n",
    "\n",
    "    def predict(self):\n",
    "        max_occur = 0\n",
    "        max_key = None\n",
    "        for key in self.predictions.keys():\n",
    "            if self.predictions[key] > max_occur:\n",
    "                max_occur = self.predictions[key]\n",
    "                max_key = key\n",
    "        return max_key\n",
    "\n",
    "\n",
    "class MiddleNode:\n",
    "    def __init__(self, question, branches):\n",
    "        self.question = question\n",
    "        self.branches = branches\n",
    "\n",
    "\n",
    "def build_tree(df, max_depth):\n",
    "    gain, question = find_best_split(df)\n",
    "\n",
    "\n",
    "    if gain == 0 or max_depth <= 0:\n",
    "        return Leaf(df)\n",
    "\n",
    "    partitions = question.partition(df)\n",
    "    partitions_nodes = [] \n",
    "    for partition in partitions:\n",
    "        temp = build_tree(partition, max_depth - 1)\n",
    "        partitions_nodes.append(temp)\n",
    "\n",
    "    return MiddleNode(question, partitions_nodes)\n",
    "\n",
    "\n",
    "\n",
    "def print_tree(node, spacing1=\"\\t\", spacing2=\"\\t\\t\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing1, node.predictions)\n",
    "        return\n",
    "    print(spacing1 + (node.question.print(spacing1)))\n",
    "    for i, possible_value in enumerate(node.question.column_possible_values):\n",
    "\n",
    "        print(spacing1 + '--> :' + str(possible_value))\n",
    "        print_tree(node.branches[i], spacing1 + spacing2)\n",
    "\n",
    "\n",
    "\n",
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predict()\n",
    "    branch_index = node.question.match_index(row)\n",
    "    return classify(row, node.branches[branch_index])\n",
    "\n",
    "\n",
    "def predict_test_set(df, node):\n",
    "    predicted_y = []\n",
    "    for row_index in range(df.shape[0]):\n",
    "        y = classify(df.iloc[row_index], node)\n",
    "        predicted_y.append(y)\n",
    "    return predicted_y\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('transfusion.data')\n",
    "df2.columns = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "df2 = change_data_set(df2, Config.N)\n",
    "train, test = split_train_test_data(df2)\n",
    "train_x, train_y = split_x_y_data(train)\n",
    "test_x, test_y = split_x_y_data(test)\n",
    "my_tree = build_tree(df=train, max_depth=2)\n",
    "# print_tree(my_tree)\n",
    "\n",
    "print(\"TRAIN:\")\n",
    "train_y_pred = predict_test_set(train, my_tree)\n",
    "train_conf = calc_confusion(y_pred=train_y_pred, y_true=train_y, n=train_y.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(train_conf), \"f1_score: \", f1_score(train_conf), \"recall_score: \", recall_score(train_conf))\n",
    "\n",
    "print(\"TEST:\")\n",
    "test_y_pred = predict_test_set(test, my_tree)\n",
    "test_conf = calc_confusion(y_pred=test_y_pred, y_true=test_y, n=test_y.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(test_conf), \"f1_score: \", f1_score(test_conf), \"recall_score: \", recall_score(test_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    Weighted Classification\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    570\n",
       "1    178\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "     همانطور که مشاهده شد، مقادیر f1score و recall بسیار پایین هستند دلیل این امر این هست که برچسب کلاس ها unbalanced هستند و داده های 1 تعداد کمتری دارند. راه حل این امر این هست که از وزن دهی در مدل هایمان استفاده کنیم، به عبارتی وزن داده های با برچسب 1 را بیشتر قرار دهیم در زیر این تغییر ایجاد شده و مشاهده می کنید recall تا 1 پیش می رود.\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Weighted Logistic Regression\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: \n",
      "accuracy_score: 0.3466666666666667  f1_score:  0.4302325581395348  recall_score:  0.9736842105263158\n",
      "TRAIN: \n",
      "accuracy_score: 0.362876254180602  f1_score:  0.41653905053598766  recall_score:  0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(a):\n",
    "    return 1/(1+ np.exp(-1 * a))\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, lr, max_iter):\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        \n",
    "    def predict(self, x):\n",
    "        z = sigmoid(np.dot(x, self.w) + self.w0)\n",
    "        return np.where(z > 0.5, 1, 0)\n",
    "\n",
    "    def fit(self, x, y, weights):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w0 = 0\n",
    "        self.n = x.shape[0]\n",
    "        self.m = x.shape[1]\n",
    "        self.w = np.zeros(self.m)\n",
    "        self.weight1 = weights['1']\n",
    "        self.weight0 = weights['0']\n",
    "        for i in range(self.max_iter):\n",
    "            yn = sigmoid(np.dot(self.x, self.w) + self.w0)\n",
    "            tmp = ((self.weight0) * yn + (self.weight1 - self.weight0) * np.multiply(yn, self.y) - (self.weight1) * self.y)\n",
    "            self.w -= self.lr * (np.dot(self.x.T, tmp) / self.n)\n",
    "            self.w0 -= self.lr * (np.sum(tmp) / self.n)\n",
    "        return self\n",
    "\n",
    "\n",
    "model = LogisticRegression(lr=0.1, max_iter=20000)\n",
    "model.fit(x_train_array, y_train_array, {'1': 9, '0': 1})\n",
    "y_pred = model.predict(x_test_array)\n",
    "print(\"TEST: \")\n",
    "test_cnf = calc_confusion(y_pred, y_test_array, y_test_array.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(test_cnf), \" f1_score: \", f1_score(test_cnf), \" recall_score: \", recall_score(test_cnf))\n",
    "\n",
    "train_y_pred = model.predict(x_train_array)\n",
    "print(\"TRAIN: \")\n",
    "train_cnf = calc_confusion(train_y_pred, y_train_array, y_train_array.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(train_cnf), \" f1_score: \", f1_score(train_cnf), \" recall_score: \", recall_score(train_cnf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Weighted Decision Tree\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "accuracy_score: 0.22742474916387959 f1_score:  0.36712328767123287 recall_score:  0.9571428571428572\n",
      "TEST:\n",
      "accuracy_score: 0.24666666666666667 f1_score:  0.3957219251336898 recall_score:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    TARGET = 'tag'\n",
    "    PRIME = '_prime'\n",
    "    Q = 'q'\n",
    "    YES = 1\n",
    "    NO = 0\n",
    "    N = 2\n",
    "    headers = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "\n",
    "\n",
    "def change_data_set(df, n):\n",
    "    for column in df.columns:\n",
    "        if column == Config.TARGET:\n",
    "            continue\n",
    "\n",
    "        def f(x):\n",
    "            min_value = df[column].min()\n",
    "            max_value = df[column].max()\n",
    "            step = (max_value - min_value) / n\n",
    "            a = min_value\n",
    "            b = a + step\n",
    "            if x < a:\n",
    "                return str(Config.Q) + \"0\"\n",
    "            for i in range(1, n):\n",
    "                if b > x >= a:\n",
    "                    return str(Config.Q) + str(i)\n",
    "                a = b\n",
    "                b = a + step\n",
    "\n",
    "            if x >= a:\n",
    "                return str(Config.Q) + str(n)\n",
    "\n",
    "        df[column + str(Config.PRIME)] = df[column].apply(lambda x: f(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Config.headers)):\n",
    "    if Config.headers[i] == Config.TARGET:\n",
    "        continue\n",
    "    Config.headers[i] = str(Config.headers[i]) + str(Config.PRIME)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, column, df):\n",
    "        self.column = column\n",
    "        self.column_possible_values = df[column].value_counts().index.tolist()\n",
    "        self.num_possible_values = len(df[column].value_counts().index.tolist())\n",
    "        self.gain_information = 0\n",
    "        self.branches_entropy = []\n",
    "\n",
    "    def partition(self, df):\n",
    "        output = list()\n",
    "        for possible_value in self.column_possible_values:\n",
    "            temp = df[df[self.column] == possible_value]\n",
    "            output.append(temp)\n",
    "        return output\n",
    "\n",
    "    def match_index(self, row):\n",
    "        df_row = row\n",
    "        row_answer_value = df_row[self.column]\n",
    "        return self.column_possible_values.index(row_answer_value)\n",
    "\n",
    "    def print(self, spacing):\n",
    "        return \"??\" + str(self.column) + \"??\\n\" + str(spacing) + \" GI: \" + str(\n",
    "            self.gain_information) + \"\\n \" + str(spacing) + \"Branches entropy: \" + str(self.branches_entropy)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"??\" + str(self.column) + \"??\"\n",
    "\n",
    "def B(q):\n",
    "    if q == 1 or q == 0:\n",
    "        return 0\n",
    "    return round(-1 * (q * np.log2(q) + (1 - q) * np.log2(1 - q)), 10)\n",
    "\n",
    "\n",
    "def remainder_util(total_elements, n_k, p_k):\n",
    "    return round((p_k + n_k) / total_elements * B(p_k / (p_k + n_k)), 10)\n",
    "\n",
    "\n",
    "def reminder(total_elements, list_of_partitions):\n",
    "    r = 0\n",
    "    partitions_entropy = []\n",
    "    for sub_df in list_of_partitions:\n",
    "        n_k_and_pk = sub_df.shape[0]\n",
    "        pk = sub_df[sub_df[Config.TARGET] == Config.YES].shape[0]\n",
    "        nk = n_k_and_pk - pk\n",
    "        t = remainder_util(total_elements, nk, pk)\n",
    "        r += t\n",
    "        partitions_entropy.append(t)\n",
    "    return r, partitions_entropy\n",
    "\n",
    "\n",
    "\n",
    "def gain(n, p, list_of_partitions):\n",
    "    r, partitions_entropy = reminder(p + n, list_of_partitions)\n",
    "    return (B(p / (n + p)) - r), partitions_entropy\n",
    "\n",
    "\n",
    "\n",
    "def find_best_split(df):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    n_and_p = df.shape[0]\n",
    "    p = df[df[Config.TARGET] == Config.YES].shape[0]\n",
    "    n = n_and_p - p\n",
    "\n",
    "    for feature in Config.headers[:-1]:\n",
    "        question = Question(feature, df)\n",
    "        question.gain_information, question.branches_entropy = gain(n, p, question.partition(df))\n",
    "        if question.gain_information > best_gain:\n",
    "            best_gain, best_question = question.gain_information, question\n",
    "    return best_gain, best_question\n",
    "\n",
    "\n",
    "def leaf_count(df, weight):\n",
    "#     unique_values_count = np.array(df[Config.TARGET].value_counts())\n",
    "    w0 = weight['0']\n",
    "    w1 = weight['1']\n",
    "    n_vals = df[Config.TARGET].value_counts()[0] * w0\n",
    "    p_vals = df[Config.TARGET].value_counts()[1] * w1\n",
    "    unique_values_count = [n_vals, p_vals]\n",
    "    unique_values_name = df[Config.TARGET].value_counts().index.tolist()\n",
    "    counts = {}\n",
    "    for i, name in enumerate(unique_values_name):\n",
    "        counts[name] = unique_values_count[i]\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, df, weight):\n",
    "        self.predictions = leaf_count(df, weight)\n",
    "\n",
    "    def predict(self):\n",
    "        max_occur = 0\n",
    "        max_key = None\n",
    "        for key in self.predictions.keys():\n",
    "            if self.predictions[key] > max_occur:\n",
    "                max_occur = self.predictions[key]\n",
    "                max_key = key\n",
    "        return max_key\n",
    "\n",
    "\n",
    "class MiddleNode:\n",
    "    def __init__(self, question, branches):\n",
    "        self.question = question\n",
    "        self.branches = branches\n",
    "\n",
    "\n",
    "def build_tree(df, max_depth, weight):\n",
    "    gain, question = find_best_split(df)\n",
    "\n",
    "\n",
    "    if gain == 0 or max_depth <= 0:\n",
    "        return Leaf(df, weight)\n",
    "\n",
    "    partitions = question.partition(df)\n",
    "    partitions_nodes = [] \n",
    "    for partition in partitions:\n",
    "        temp = build_tree(partition, max_depth - 1, weight)\n",
    "        partitions_nodes.append(temp)\n",
    "\n",
    "    return MiddleNode(question, partitions_nodes)\n",
    "\n",
    "\n",
    "\n",
    "def print_tree(node, spacing1=\"\\t\", spacing2=\"\\t\\t\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing1, node.predictions)\n",
    "        return\n",
    "    print(spacing1 + (node.question.print(spacing1)))\n",
    "    for i, possible_value in enumerate(node.question.column_possible_values):\n",
    "\n",
    "        print(spacing1 + '--> :' + str(possible_value))\n",
    "        print_tree(node.branches[i], spacing1 + spacing2)\n",
    "\n",
    "\n",
    "\n",
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predict()\n",
    "    branch_index = node.question.match_index(row)\n",
    "    return classify(row, node.branches[branch_index])\n",
    "\n",
    "\n",
    "def predict_test_set(df, node):\n",
    "    predicted_y = []\n",
    "    for row_index in range(df.shape[0]):\n",
    "        y = classify(df.iloc[row_index], node)\n",
    "        predicted_y.append(y)\n",
    "    return predicted_y\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('transfusion.data')\n",
    "df2.columns = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "df2 = change_data_set(df2, Config.N)\n",
    "train, test = split_train_test_data(df2)\n",
    "train_x, train_y = split_x_y_data(train)\n",
    "test_x, test_y = split_x_y_data(test)\n",
    "my_tree = build_tree(df=train, max_depth=2, weight={'1':9, '0':1})\n",
    "# print_tree(my_tree)\n",
    "\n",
    "print(\"TRAIN:\")\n",
    "train_y_pred = predict_test_set(train, my_tree)\n",
    "train_conf = calc_confusion(y_pred=train_y_pred, y_true=train_y, n=train_y.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(train_conf), \"f1_score: \", f1_score(train_conf), \"recall_score: \", recall_score(train_conf))\n",
    "\n",
    "print(\"TEST:\")\n",
    "test_y_pred = predict_test_set(test, my_tree)\n",
    "test_conf = calc_confusion(y_pred=test_y_pred, y_true=test_y, n=test_y.shape[0])\n",
    "print(\"accuracy_score:\", accuracy_score(test_conf), \"f1_score: \", f1_score(test_conf), \"recall_score: \", recall_score(test_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    AdaBoost\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: \n",
      "accuracy_score:  0.25333333333333335  f1_score: 0.4042553191489362  recall_score:  1.0\n",
      "TRAIN: \n",
      "accuracy_score:  0.23411371237458195  f1_score: 0.3794037940379404  recall_score:  1.0\n"
     ]
    }
   ],
   "source": [
    "class AdaBoost:  \n",
    "    def __init__(self,samples=10):\n",
    "        self.samples = samples\n",
    "        self.models = [None] * samples\n",
    "        \n",
    "    def predict(self, df):\n",
    "        y = 0\n",
    "        for s in range(self.samples):\n",
    "            alpha, tree = self.models[s]\n",
    "            y += alpha * np.array(predict_test_set(df, tree))\n",
    "        y_ = np.where(np.vectorize(lambda i: 1 if i>= 0 else -1)(y) == 1, 1, -1)\n",
    "        return y_\n",
    "        \n",
    "    def fit(self, df, x, y):    \n",
    "        N = y.shape[0]\n",
    "        w = np.array([1/N for i in range(N)])\n",
    "        for m in range(self.samples):\n",
    "            my_tree = build_tree(df=df, max_depth=1)\n",
    "            y_pred = predict_test_set(df, my_tree)\n",
    "            em = sum([w[i] * (1 if y[i] != y_pred[i] else 0) for i in range(N)]) / sum(w)\n",
    "            alpha = np.log((1 - em) / em)  \n",
    "            w = [w[i] * np.exp(alpha * (1 if y[i] != y_pred[i] else 0)) for i in range(N)] \n",
    "            self.models[m] = (alpha, my_tree)\n",
    "\n",
    "\n",
    "df3 = pd.read_csv('transfusion.data')\n",
    "df3.columns = ['Recency', 'Frequency', 'Monetary', 'Time', 'tag']\n",
    "df3 = change_data_set(df3, Config.N)\n",
    "train, test = split_train_test_data(df3)\n",
    "train_x, train_y = split_x_y_data(train)\n",
    "test_x, test_y = split_x_y_data(test)\n",
    "clf = AdaBoost(samples=10)\n",
    "clf.fit(train, train_x, train_y)\n",
    "\n",
    "print(\"TEST: \")\n",
    "y_test_pred = clf.predict(test)\n",
    "test_conf = calc_confusion(y_pred=y_test_pred, y_true=test_y, n=test_y.shape[0])\n",
    "print(\"accuracy_score: \", accuracy_score(test_conf), \" f1_score:\",f1_score(test_conf) , \" recall_score: \", recall_score(test_conf))\n",
    "\n",
    "print(\"TRAIN: \")\n",
    "y_train_pred = clf.predict(train)\n",
    "train_conf = calc_confusion(y_pred=y_train_pred, y_true=train_y, n=train_y.shape[0])\n",
    "print(\"accuracy_score: \", accuracy_score(train_conf), \" f1_score:\",f1_score(train_conf) , \" recall_score: \", recall_score(train_conf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
